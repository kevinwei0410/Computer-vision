# -*- coding: utf-8 -*-
"""homework4

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h03y1zzLjb1vm-cWEUq23isWt3sfp4nI
"""

!git clone https://github.com/bearpaw/clothing-co-parsing.git

from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf
import os
import matplotlib.pyplot as plt
import numpy as np
import scipy.io
from IPython.display import clear_output, display
import glob
from sklearn.model_selection import train_test_split
from tensorflow.keras.applications.vgg16 import preprocess_input
import cv2

path_to_image_dataset = "clothing-co-parsing/photos"
path_to_annotation_dataset = "clothing-co-parsing/annotations/pixel-level"
path_to_save_temp = "clothing-co-parsing/save_temp/"



def training_image_generator(images):
    for image_file,annotation_file in images:
        yield (image_file,annotation_file)

def imread(filename,channels=0):
    image = tf.io.read_file(filename)
    image = tf.image.decode_jpeg(image,channels=channels)
    if channels != 0 and tf.shape(image)[-1]!=channels:
        image = image[:,:,:channels]
    return image


def load_labeled_samples(x, y, augmented = True, preprocessing = None, image_size=(128,128)):
    x_train = tf.image.resize(imread(x,3), image_size)
    y_train = tf.image.resize(imread(y), image_size,method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)    
    if augmented:
        if tf.random.uniform(()) > 0.5:
            x_train = tf.image.flip_left_right(x_train)
            y_train = tf.image.flip_left_right(y_train)
    
    if preprocessing is None:
        x_train = tf.cast(x_train, tf.float32) / 255.0
    else:
        x_train = preprocessing(x_train)
        
    #y_train -= 1
    return (x_train,y_train)


#########################


filename_list = []

files = os.listdir(path_to_image_dataset)
files.sort(key=lambda x: int(x.split('.')[0]))
for path in files:
    tmp = os.path.join(path_to_image_dataset, path)
    filename_list.append(tmp)

filename_list2 = glob.glob(os.path.join(path_to_annotation_dataset,"*.mat"))



filename_list3 = []
for n in filename_list2:
    image = scipy.io.loadmat(n)
    image = np.array(image['groundtruth'])
    new_filename = n.split(os.sep)[-1].split('.')[0]+'.png'
    #print(new_filename)
    cv2.imwrite(path_to_save_temp + new_filename, image)
    cv2.imwrite(new_filename, image)
    filename_list3.append(new_filename)

#training_image_files = np.array([f.split(os.sep)[-1] for f in filename_list3])
#########################


label_file = []
for i in filename_list3:
  label_file.append(imread(i))



np.random.seed(2020)
idx = np.random.permutation(len(label_file))+1
training_idx = idx[:int((len(label_file)/4) * 3)]
testing_idx  = idx[int((len(label_file)/4) * 3):]

#training_image_files = np.array([f.split(os.sep)[-1] for f in filename_list])
#training_image_files = training_image_files[np.random.permutation(training_image_files.size)]
#training_images, valid_images = train_test_split(np.array([(os.path.join(path_to_image_dataset,image_file),os.path.join(path_to_annotation_dataset,'.'.join(image_file.split('.')[:-1]+['png']))) for image_file in training_image_files]),test_size=0.1)
print(filename_list3)
training_image_files = np.array([(os.path.join(path_to_image_dataset,'.'.join(image_file.split('.')[:-1]+['jpg'])),(path_to_save_temp + image_file)) for image_file in filename_list3])
print(training_image_files)
training_images, valid_images = training_image_files[training_idx - 1], training_image_files[testing_idx]

#training_images = []
#valid_images = []
#for i in training_idx:
#  training_images.append([filename_list[i - 1], filename_list3[i - 1]])
#for i in testing_idx:
#  valid_images.append([filename_list[i - 1], filename_list3[i - 1]])


#training_images = np.array(training_images)
#valid_images = np.array(valid_images)



#print(training_images)

print('training examples:{} validation examples:{}'.format(len(training_idx),len(testing_idx)))

BATCH_SIZE = 64
EPOCHS     = 10


train_ds = tf.data.Dataset.from_generator(lambda : training_image_generator(training_images),(tf.string, tf.string)).cache()
train_ds = train_ds.map(lambda x,y: load_labeled_samples(x,y,preprocessing=preprocess_input), num_parallel_calls=tf.data.experimental.AUTOTUNE).take(-1).repeat(EPOCHS).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

valid_ds = tf.data.Dataset.from_generator(lambda : training_image_generator(valid_images),(tf.string, tf.string)).cache()
valid_ds = valid_ds.map(lambda x,y: load_labeled_samples(x,y,augmented=False,preprocessing=preprocess_input), num_parallel_calls=tf.data.experimental.AUTOTUNE).take(-1).repeat(EPOCHS).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

def upsample(filters, size):
    return [tf.keras.layers.Conv2DTranspose(filters, size, strides=2,padding='same'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.ReLU()]



def def_unet(classes,height,width,channels,base_model,layer_names,name):
    base_model = tf.keras.Model(inputs=base_model.input,outputs = [base_model.output]+
                                                        [base_model.get_layer(na).output for na in reversed(layer_names)])
    base_model.summary()
    inputs = tf.keras.layers.Input(shape=(height,width,channels))
    skips  = base_model(inputs)
    x      = skips[0]
    
    # U型的底部處理
    x      = tf.keras.layers.Conv2D(512,(3,3),padding='same',activation='relu')(x)
    for layer in upsample(512,(3,3)):
        x=layer(x)        
    #upsampling network
    for ch,skip in zip([256,128,64,32],skips[1:-1]):
        x = tf.keras.layers.Concatenate()([x,skip])
        for layer in upsample(ch,(3,3)):
            x=layer(x)        
            
    x = tf.keras.layers.Concatenate()([x,skips[-1]]) 
    x = tf.keras.layers.Conv2D(96,(1,1),padding='same')(x)        
    #最後輸出        
    x = tf.keras.layers.Conv2D(classes,(3,3),padding='same')(x)        
    
    unet = tf.keras.Model(inputs=inputs,outputs=x,name=name)
    unet.summary()
    base_model.trainable = False
    unet.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer='adam',metrics=['accuracy'])
    return unet

vgg16_layer_names = [
    'block1_conv2', # 1
    'block2_conv2', # 1/2
    'block3_conv3', # 1/4
    'block4_conv3', # 1/8
    'block5_conv3', # 1/16
]

unet_vgg16 = def_unet(59,128,128,3,tf.keras.applications.VGG16(include_top = False),vgg16_layer_names,'unet-vgg16')

VALIDATION_STEPS = len(valid_images)//BATCH_SIZE
STEPS_PER_EPOCH  = len(training_images)//BATCH_SIZE
unet_vgg16_history    = unet_vgg16.fit(train_ds, epochs= EPOCHS,
                          steps_per_epoch = STEPS_PER_EPOCH,
                          validation_steps=VALIDATION_STEPS,
                          validation_data= valid_ds,
                          callbacks=[])#[DisplayCallback()])

def create_prediction_mask(pred_mask):
    pred_mask = tf.argmax(pred_mask, axis=-1)
    pred_mask = pred_mask[..., tf.newaxis]
    return pred_mask

def show_predictions(model, dataset, num=1):
    result = []
    min = 1
    max = 0
    for image, mask in dataset.take(num):
        pred_mask = model.predict(image)
        for i in range(image.shape[0]):
            result.append(image[i])
            result.append(mask[i])
            result.append(create_prediction_mask(pred_mask[i]))
            m = tf.keras.metrics.MeanIoU(num_classes=59)
            _ = m.update_state(result[i*3+1], result[i*3+2])
            print(m.result().numpy())
            if m.result().numpy() < min:
              min = m.result().numpy()
            if m.result().numpy() > max:
              max = m.result().numpy()
    display_image_mask(result,6)
    print("the worst:", min)
    print("the best:", max)
    return

def display_image_mask(display_list,col=8):
    plt.figure(figsize=(2*col, 2*(len(display_list)+col-1)//col))
    for i in range(len(display_list)):
        plt.subplot((len(display_list)+col-1)//col, col, i+1)
        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))
        plt.axis(False)
    plt.tight_layout()
    plt.show()
    return

def plot_history(history, name):
    
    epochs = range(len(history['loss']))

    plt.figure(figsize=(10,4))
    plt.subplot(1,2,1)
    plt.plot(epochs, history['loss'], label='Training loss')
    plt.plot(epochs, history['val_loss'], label='Validation loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss Value')
    plt.grid(True)
    plt.legend()
    plt.title('Training/validation loss of {}'.format(name))

    plt.subplot(1,2,2)
    plt.plot(epochs, history['accuracy'], label='Training accuracy')
    plt.plot(epochs, history['val_accuracy'], label='Validation accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.ylim([0, 1])
    plt.legend()
    plt.title('Training/validation accuracy of {}'.format(name))
    plt.grid(True)

    plt.tight_layout()
    plt.show()
    return

plot_history(unet_vgg16_history.history, 'unet-vgg16')

show_predictions(unet_vgg16,valid_ds)